{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# prefer_gpu() https://spacy.io/api/top-level#spacy.prefer_gpu?\n",
    "\n",
    "path = '/Users/Svesketerning/Google-Drev/experiments'\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_wordcount_branch(focusword_df):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    for i in focusword_df['mainmathcat'].unique():\n",
    "        values_context = []\n",
    "        a = len(focusword_df.loc[(focusword_df['mainmathcat'] == i)])\n",
    "        b = df_arxiv.loc[(df_arxiv['mainmathcat'] == i)][['outer','theorem','meta',\n",
    "                                                               'proof','other']].sum().sum()\n",
    "        if b>0:\n",
    "            c = a/b * 10**6\n",
    "        else:\n",
    "            c = None\n",
    "        result.append({'mainmathcat': i, 'focuswords': c})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    return df\n",
    "#from explain_words_extraction.ipynb import word_extract\n",
    "def word_extract(dataframe_context,focus_words):\n",
    "    result = []\n",
    "    #contexts = [x for x in dataframe_context.columns]\n",
    "    contexts = ['outer', 'theorem', 'meta', 'proof', 'other']\n",
    "    for index in tqdm(range(len(dataframe_context.index))):\n",
    "        for c in contexts:\n",
    "            sentences = nltk.sent_tokenize(dataframe_context[c][index])\n",
    "            for sent in sentences:\n",
    "                sent = sent.lower()\n",
    "                overlap = [x for x in focus_words if x in sent]\n",
    "                if len(overlap)>0:\n",
    "                    arc_id = df_contexts['id'][index]\n",
    "                    result.append({'id':arc_id, # NOTE THAT YOU HAVE TO LOAD ARXIV DATABASE FILE AS df_arxiv!!\n",
    "                                   'mainmathcat': df_arxiv.loc[df_arxiv['id'] == arc_id]['mainmathcat'].item(),\n",
    "                                   'context': c, 'sentence': sent, 'focuswords': \",\".join(overlap)})\n",
    "    df = pd.DataFrame(result)\n",
    "    df = df.set_index('id')\n",
    "    return df \n",
    "# From explanations-theorems-proofs - extract rows with sentences that have a focusword\n",
    "def sentence_extract(df,focuswords, contexts = None, remove_focuswords = False):\n",
    "    if contexts is not None: # Focus on context\n",
    "        df = df[df['context'].isin(contexts)]\n",
    "    for i in tqdm(df.index):\n",
    "        sent = df.loc[i,'sentence']\n",
    "        tokenize_sent = nltk.word_tokenize(sent)\n",
    "        if any(x in focuswords for x in tokenize_sent) is remove_focuswords:\n",
    "            df = df.drop(index=i)\n",
    "    return df \n",
    "def adj_nouns(df, focus_noun, contexts = None): # Looks for adjectives around a noun in \"noun\"_raw-df files\n",
    "    result = []\n",
    "    df = df.reset_index()\n",
    "    if contexts is not None: # Focus on context\n",
    "        df = df[df['context'].isin(contexts)]\n",
    "    for i in tqdm(df.index):\n",
    "        doc = nlp(df.loc[i,'sentence'])\n",
    "        for chunk in doc.noun_chunks:\n",
    "            if chunk.root.text in focus_noun:\n",
    "                for token in chunk:\n",
    "                    if token.pos_ in 'ADJ':\n",
    "                        result.append({'id':df.loc[i,'id'],'mainmathcat': df.loc[i,'mainmathcat'],\n",
    "                                       'context': df.loc[i,'context'], 'sentence': df.loc[i,'sentence'],\n",
    "                                       'focuswords': df.loc[i,'focuswords'],'adjective': token.text})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    #df = df.set_index('id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from explain words extraction\n",
    "# Load latest context and ArXiv database file\n",
    "LatestContextFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/arxiv_contexts*'),key=os.path.getctime)\n",
    "df_contexts = pd.read_feather(LatestContextFile)\n",
    "\n",
    "LatestDatabaseFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/arxiv_extended_database*'),key=os.path.getctime)\n",
    "df_arxiv = pd.read_feather(LatestDatabaseFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks at adjectives connected to proofs \n",
    "#### Using the adj_nouns function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0791735dfa442ab97d9a55e81d07ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Creates and saves the proof_fullraw in database-files\n",
    "proof_word = ['proof']\n",
    "proof_raw_df = word_extract(df_contexts,proof_word) # Computational heavy\n",
    "proof_raw_df = proof_raw_df.reset_index()\n",
    "proof_raw_df.to_feather(path+'/database-files/proof_fullraw'+timestr+'.feather')\n",
    "\n",
    "# Creates and saves the understa_fullraw in database-files\n",
    "#understa_raw_df = word_extract(df_contexts,['understa']) \n",
    "#understa_raw_df = understa_raw_df.reset_index()\n",
    "#understa_raw_df = proof_raw_df.reset_index()\n",
    "#understa_raw_df.to_feather(path+'/database-files/understa_fullraw'+timestr+'.feather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latest understa and proof file\n",
    "LatestUnderstaFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/understa_fullraw*'),key=os.path.getctime)\n",
    "understa_raw_df = pd.read_feather(LatestUnderstaFile)\n",
    "\n",
    "LatestProofFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/proof_fullraw*'),key=os.path.getctime)\n",
    "proof_raw_df = pd.read_feather(LatestProofFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7b73d8aab546fca531d8f3b68fccde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87956.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "proofadj_df = adj_nouns(proof_raw_df,contexts = ['outer','meta','other'],focus_noun = ['proof'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(proofadj_df[proofadj_df['adjective'].isin(['theoretic','theoretical'])].sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f672183ff86642f9af8082b06f2482f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87956.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Using adj_nouns and makes a dataframe of counts. \n",
    "proofadj_df = adj_nouns(proof_raw_df,contexts = ['outer','meta','other'],focus_noun = ['proof'])\n",
    "count_adj = proofadj_df['adjective'].value_counts().to_frame()\n",
    "count_adj.index.name = 'adjective'\n",
    "count_adj = count_adj.rename(columns={'adjective': 'count'})\n",
    "count_adj['pct'] = ((count_adj['count'] / count_adj['count'].sum())*100).round(2)\n",
    "count_adj = count_adj.reset_index()\n",
    "count_adj.to_feather(path+'/armchair/count_pct_adj_df'+timestr+'.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "LatestCountAdjectiveFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/armchair/count_pct_adj_df*'),key=os.path.getctime)\n",
    "count_adj = pd.read_feather(LatestCountAdjectiveFile)\n",
    "\n",
    "# Picked from criteria count>=20. - HARDCODED, BUT ALSO CATEGORIES CHOSEN BY HAND\n",
    "meta = ['new', 'alternative', 'above', 'same', 'different', 'original', \n",
    " 'first', 'previous', 'similar', 'alternate', 'second', 'following', 'classical', 'standard', \n",
    " 'such','main', 'actual', 'whole']\n",
    "\n",
    "how_adj = ['direct','complete','full', 'formal','constructive', \n",
    "           'independent', 'inductive','bijective', 'uniqueness','theoretical', 'theoretic']\n",
    "\n",
    "\n",
    "what_adj = ['simple','short','detailed', 'elementary','rigorous','simpler',\n",
    "            'combinatorial','geometric', 'algebraic','shorter', 'easy', 'general', \n",
    "            'quick', 'analytic','simplified', 'elegant', 'unified','technical',\n",
    "            'straightforward', 'explicit','brief', 'probabilistic', \n",
    "            'mathematical']\n",
    "\n",
    "\n",
    "a = count_adj.loc[count_adj['adjective'].isin(meta)].sum(numeric_only = True).to_frame(name = 'Meta adjectives').transpose()\n",
    "b = count_adj.loc[count_adj['adjective'].isin(how_adj)].sum(numeric_only = True).to_frame(name = 'Objective adjectives').transpose()\n",
    "c = count_adj.loc[count_adj['adjective'].isin(what_adj)].sum(numeric_only = True).to_frame(name = 'Subjective adjectives').transpose()\n",
    "adj_compund = a.append([b,c])\n",
    "adj_compund.drop('pct', 1, inplace = True)\n",
    "total = adj_compund['count'].sum()\n",
    "adj_compund['Percentage'] = [adj_compund['count'][0]/total*100,\n",
    "                      adj_compund['count'][1]/total*100,\n",
    "                      adj_compund['count'][2]/total*100]\n",
    "adj_compund['Percentage'] = adj_compund['Percentage'].round(1)\n",
    "\n",
    "\n",
    "# Saves both as tables in /tex folder\n",
    "count_adj.to_latex(path+'/tex/count_adjectives_freq'+timestr+'.tex')\n",
    "adj_compund.to_latex(path+'/tex/adjectives_classified_freq'+timestr+'.tex')\n",
    "# Saves both of them to /armchair folder as dataframes\n",
    "adj_compund = adj_compund.reset_index()\n",
    "\n",
    "adj_compund.to_feather(path+'/armchair/count_pct_categorized_adj_df'+timestr+'.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factors</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aesthetic</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Usefulness</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intricacy</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precision</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Factors  Counts\n",
       "0   Aesthetic      73\n",
       "1  Usefulness      39\n",
       "2   Intricacy     481\n",
       "3   Precision     218"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count_adj = count_adj.set_index('adjective')\n",
    "f1 = ['ingenious', 'striking', 'inspired', 'creative', # Aesthetic\n",
    "     'beautiful', 'profound', 'elegant','deep',\n",
    "     'innovative','sublime','charming','clever','appealing',\n",
    "     'pleasing','enlightning','insightful','bold','strong',\n",
    "     'subtle','delicate','ambitous','cute','sharp']\n",
    "f2 = ['practical','informative','applicable','intuitive',  #Usefullness\n",
    "     'natural','illustrative','efficient','useful',\n",
    "     'explanatory','conceptual','plausible','fruitful']\n",
    "f3 = ['difficult','dense','intricate','confusing', # Intricacy\n",
    "     'tedious','elaborate','simple','abstract','non-trivial'] \n",
    "f4 = ['precise','careful','rigorous','accurate','clear',\n",
    "     'meticulous','polished','unambigous'] # Precision \n",
    "\n",
    "data = {'Factors': ['Aesthetic', 'Usefulness', 'Intricacy', 'Precision'],\n",
    "        'Counts': [count_adj[count_adj['adjective'].isin(f1)]['count'].sum(),\n",
    "                   count_adj[count_adj['adjective'].isin(f2)]['count'].sum(),\n",
    "                   count_adj[count_adj['adjective'].isin(f3)]['count'].sum(),\n",
    "                   count_adj[count_adj['adjective'].isin(f4)]['count'].sum()]\n",
    "       }\n",
    "ramos_comparison_df = pd.DataFrame.from_dict(data)\n",
    "ramos_comparison_df.to_latex(path+'/tex/ramos_comparison'+timestr+'.tex', index = False)\n",
    "ramos_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factors</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aesthetic</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intricacy</td>\n",
       "      <td>1621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Usefulness</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Factors  Counts\n",
       "0   Aesthetic     474\n",
       "1   Intricacy    1621\n",
       "2   Precision     755\n",
       "3  Usefulness      34"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intricacy =['simple', 'short', 'elementary', 'simpler', \n",
    " 'easy', 'quick', 'shorter', 'simplified', 'straightforward', 'brief']\n",
    "aesthetic = ['elegant', 'technical', 'geometric', 'algebraic', \n",
    "             'analytic', 'combinatorial', 'probabilistic', 'mathematical'] \n",
    "precision = ['detailed', 'rigorous', 'formal', 'general', 'explicit']\n",
    "usefulness = ['unified']\n",
    "data = {'Factors': ['Aesthetic', 'Intricacy', 'Precision', 'Usefulness'],\n",
    "        'Counts': [count_adj[count_adj['adjective'].isin(aesthetic)]['count'].sum(),\n",
    "                   count_adj[count_adj['adjective'].isin(intricacy)]['count'].sum(),\n",
    "                   count_adj[count_adj['adjective'].isin(precision)]['count'].sum(),\n",
    "                  count_adj[count_adj['adjective'].isin(usefulness)]['count'].sum()]\n",
    "       }\n",
    "ramos_comparison_df2 = pd.DataFrame.from_dict(data)\n",
    "ramos_comparison_df2.to_latex(path+'/tex/ramos_comparison2'+timestr+'.tex', index = False)\n",
    "ramos_comparison_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is it proofs or figures/diagrams that provides understanding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load explanation_df\n",
    "LatestExplanationFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/explain_fullraw*'),key=os.path.getctime)\n",
    "explanation_df = pd.read_feather(LatestExplanationFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94efd1ae55b64c039311b0f7bd9eb76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11291.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb04f81822cf4497a15eed182ded9db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11291.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Times figure and proof are mentioned in explanation contexts\n",
    "figure_sent_df = sentence_extract(explanation_df, focuswords = ['figure','figures'],\n",
    "                                   contexts = None, remove_focuswords = False)\n",
    "proof_sent_df = sentence_extract(explanation_df, focuswords = ['proof','proofs'], \n",
    "                                    contexts = None, remove_focuswords = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure_raw_df = word_extract(df_contexts,['figure']) # All the times figure is mentioned - in order to normalize\n",
    "#proof_only_raw_df = word_extract(df_contexts,['proof'])\n",
    "\n",
    "\n",
    "proof_only_raw_df = proof_only_raw_df.reset_index()\n",
    "figure_raw_df = figure_raw_df.reset_index()\n",
    "proof_only_raw_df.to_feather(path+'/database-files/proof_only_fullraw'+timestr+'.feather') # save as feather\n",
    "figure_raw_df.to_feather(path+'/database-files/figure_fullraw'+timestr+'.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LatestProofONLYFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/proof_only_fullraw*'),key=os.path.getctime)\n",
    "proof_only_raw_df = pd.read_feather(LatestProofONLYFile)\n",
    "\n",
    "LatesFigureFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/figure_fullraw*'),key=os.path.getctime)\n",
    "figure_raw_df = pd.read_feather(LatesFigureFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now have everything we need - times proof/figure is mentioned in expla/understa contexts and how many times they are used in total. We can see it is more often authors uses a explanation word in regards to a proof than to a figure, but nothing is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_mention = len(figure_raw_df)\n",
    "proof_mention = len(proof_only_raw_df) # How many times proof and proofs are used - in order to normalize\n",
    "figure_explanation = len(figure_sent_df)\n",
    "proof_explanation = len(proof_sent_df)\n",
    "# Everything we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Estimate   SE   LCB    UCB  p-value\n",
      "--------------------------------------------------\n",
      "Odds ratio        1.165        0.979 1.386   0.085\n",
      "Log odds ratio    0.153 0.089 -0.021 0.327   0.085\n",
      "Risk ratio        1.164        0.979 1.384   0.085\n",
      "Log risk ratio    0.152 0.088 -0.021 0.325   0.085\n",
      "-------------------------------------------------- 0.5434362323629283 0.466434973477227\n"
     ]
    }
   ],
   "source": [
    "# G-test\n",
    "cont_tbl = [[proof_explanation,proof_mention],[figure_explanation,figure_mention]]\n",
    "t22 = sm.stats.Table2x2(cont_tbl)\n",
    "print(t22.summary(),proof_explanation/proof_mention*100,figure_explanation/figure_mention*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of Obvious - Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mainmathcat</th>\n",
       "      <th>focuswords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>math.MG</td>\n",
       "      <td>83.690412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>math.PR</td>\n",
       "      <td>93.221894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>math.AP</td>\n",
       "      <td>94.814024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>math.GT</td>\n",
       "      <td>95.132317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>math.NA</td>\n",
       "      <td>95.837193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>math.OC</td>\n",
       "      <td>111.919972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>math.RT</td>\n",
       "      <td>112.144805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>math.HO</td>\n",
       "      <td>112.585847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>math.ST</td>\n",
       "      <td>113.373482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>math.DS</td>\n",
       "      <td>116.093658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>math.DG</td>\n",
       "      <td>120.431016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>math.QA</td>\n",
       "      <td>129.675810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>math.CA</td>\n",
       "      <td>144.656900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>math.IT</td>\n",
       "      <td>150.453354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>math.SG</td>\n",
       "      <td>152.724218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>math.MP</td>\n",
       "      <td>155.677299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>math.CO</td>\n",
       "      <td>157.234180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>math.KT</td>\n",
       "      <td>170.627288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>math.GM</td>\n",
       "      <td>177.602368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>math.AC</td>\n",
       "      <td>177.872643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>math.NT</td>\n",
       "      <td>179.948796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>math.GR</td>\n",
       "      <td>203.056737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>math.CV</td>\n",
       "      <td>206.631323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>math.RA</td>\n",
       "      <td>211.704219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>math.FA</td>\n",
       "      <td>227.936723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>math.AG</td>\n",
       "      <td>230.161113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>math.AT</td>\n",
       "      <td>252.360903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>math.OA</td>\n",
       "      <td>263.251226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>math.LO</td>\n",
       "      <td>263.483320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>math.SP</td>\n",
       "      <td>271.987255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>math.CT</td>\n",
       "      <td>311.212124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>math.GN</td>\n",
       "      <td>315.509342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mainmathcat  focuswords\n",
       "17     math.MG   83.690412\n",
       "0      math.PR   93.221894\n",
       "4      math.AP   94.814024\n",
       "10     math.GT   95.132317\n",
       "25     math.NA   95.837193\n",
       "1      math.OC  111.919972\n",
       "7      math.RT  112.144805\n",
       "11     math.HO  112.585847\n",
       "2      math.ST  113.373482\n",
       "12     math.DS  116.093658\n",
       "15     math.DG  120.431016\n",
       "28     math.QA  129.675810\n",
       "5      math.CA  144.656900\n",
       "13     math.IT  150.453354\n",
       "30     math.SG  152.724218\n",
       "8      math.MP  155.677299\n",
       "9      math.CO  157.234180\n",
       "29     math.KT  170.627288\n",
       "31     math.GM  177.602368\n",
       "6      math.AC  177.872643\n",
       "3      math.NT  179.948796\n",
       "16     math.GR  203.056737\n",
       "14     math.CV  206.631323\n",
       "21     math.RA  211.704219\n",
       "23     math.FA  227.936723\n",
       "18     math.AG  230.161113\n",
       "26     math.AT  252.360903\n",
       "20     math.OA  263.251226\n",
       "22     math.LO  263.483320\n",
       "27     math.SP  271.987255\n",
       "24     math.CT  311.212124\n",
       "19     math.GN  315.509342"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obvious_raw_df = word_extract(df_contexts,['obvious'])\n",
    "obvious_freq_df = freq_wordcount_branch(obvious_raw_df)\n",
    "\n",
    "obvious_raw_df = word_extract(df_contexts,['obvious'])\n",
    "obvious_freq_df = freq_wordcount_branch(obvious_raw_df)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "obvious_freq_df.sort_values('focuswords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
