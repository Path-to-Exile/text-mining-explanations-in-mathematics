{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# prefer_gpu() https://spacy.io/api/top-level#spacy.prefer_gpu?\n",
    "\n",
    "path = '/Users/Svesketerning/Google-Drev/experiments'\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_wordcount_branch(focusword_df):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    for i in focusword_df['mainmathcat'].unique():\n",
    "        values_context = []\n",
    "        a = len(focusword_df.loc[(focusword_df['mainmathcat'] == i)])\n",
    "        b = df_arxiv.loc[(df_arxiv['mainmathcat'] == i)][['outer','theorem','meta',\n",
    "                                                               'proof','other']].sum().sum()\n",
    "        if b>0:\n",
    "            c = a/b * 10**6\n",
    "        else:\n",
    "            c = None\n",
    "        result.append({'mainmathcat': i, 'focuswords': c})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    return df\n",
    "#from explain_words_extraction.ipynb import word_extract\n",
    "def word_extract(dataframe_context,focus_words):\n",
    "    result = []\n",
    "    contexts = [x for x in dataframe_context.columns]\n",
    "    for index in range(len(dataframe_context.index)):\n",
    "        for c in contexts:\n",
    "            sentences = nltk.sent_tokenize(dataframe_context[c][index])\n",
    "            for sent in sentences:\n",
    "                sent = sent.lower()\n",
    "                overlap = [x for x in focus_words if x in sent]\n",
    "                if len(overlap)>0:\n",
    "                    arc_id = df_contexts['id'][index]\n",
    "                    result.append({'id':arc_id, # NOTE THAT YOU HAVE TO LOAD ARXIV DATABASE FILE AS df_arxiv!!\n",
    "                                   'mainmathcat': df_arxiv.loc[df_arxiv['id'] == arc_id]['mainmathcat'].item(),\n",
    "                                   'context': c, 'sentence': sent, 'focuswords': \",\".join(overlap)})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=['id']) for i in range(len(result))])\n",
    "    df = df.set_index('id')\n",
    "    return df \n",
    "# From explanations-theorems-proofs - extract rows with sentences that have a focusword\n",
    "def sentence_extract(df,focuswords, contexts = None, remove_focuswords = False):\n",
    "    if contexts is not None: # Focus on context\n",
    "        df = df[df['context'].isin(contexts)]\n",
    "    for i in df.index:\n",
    "        sent = df.loc[i,'sentence']\n",
    "        tokenize_sent = nltk.word_tokenize(sent)\n",
    "        if any(x in focuswords for x in tokenize_sent) is remove_focuswords:\n",
    "            df = df.drop(index=i)\n",
    "    return df \n",
    "def adj_nouns(df, focus_noun, contexts = None): # Looks for adjectives around a noun in \"noun\"_raw-df files\n",
    "    result = []\n",
    "    df = df.reset_index()\n",
    "    if contexts is not None: # Focus on context\n",
    "        df = df[df['context'].isin(contexts)]\n",
    "    for i in df.index:\n",
    "        doc = nlp(df.loc[i,'sentence'])\n",
    "        for chunk in doc.noun_chunks:\n",
    "            if chunk.root.text in focus_noun:\n",
    "                for token in chunk:\n",
    "                    if token.pos_ in 'ADJ':\n",
    "                        result.append({'id':df.loc[i,'id'],'mainmathcat': df.loc[i,'mainmathcat'],\n",
    "                                       'context': df.loc[i,'context'], 'sentence': df.loc[i,'sentence'],\n",
    "                                       'focuswords': df.loc[i,'focuswords'],'adjective': token.text})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    #df = df.set_index('id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from explain words extraction\n",
    "# Load latest context and ArXiv database file\n",
    "LatestContextFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/arxiv_contexts*'),key=os.path.getctime)\n",
    "df_contexts = pd.read_feather(LatestContextFile)\n",
    "\n",
    "LatestDatabaseFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/arxiv_extended_database*'),key=os.path.getctime)\n",
    "df_arxiv = pd.read_feather(LatestDatabaseFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks at adjectives connected to proofs \n",
    "#### Using the adj_nouns function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates and saves the proof_fullraw in database-files\n",
    "proof_word = ['proof']\n",
    "proof_raw_df = word_extract(df_contexts,proof_word) # Computational heavy\n",
    "proof_raw_df = proof_raw_df.reset_index()\n",
    "proof_raw_df.to_feather(path+'/database-files/proof_fullraw'+timestr+'.feather')\n",
    "\n",
    "# Creates and saves the understa_fullraw in database-files\n",
    "understa_raw_df = word_extract(df_contexts,['understa']) \n",
    "understa_raw_df = understa_raw_df.reset_index()\n",
    "understa_raw_df = proof_raw_df.reset_index()\n",
    "understa_raw_df.to_feather(path+'/database-files/understa_fullraw'+timestr+'.feather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load latest understa and proof file\n",
    "LatestUnderstaFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/understa_fullraw*'),key=os.path.getctime)\n",
    "understa_raw_df = pd.read_feather(LatestUnderstaFile)\n",
    "\n",
    "LatestProofFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/proof_fullraw*'),key=os.path.getctime)\n",
    "proof_raw_df = pd.read_feather(LatestProofFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using adj_nouns and makes a dataframe of counts. \n",
    "proofadj_df = adj_nouns(proof_raw_df,contexts = ['outer','meta','other'],focus_noun = ['proof'])\n",
    "count_adj = proofadj_df['adjective'].value_counts().to_frame()\n",
    "count_adj.index.name = 'adjective'\n",
    "count_adj = count_adj.rename(columns={'adjective': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_adj['pct'] = ((count_adj['count'] / count_adj['count'].sum())*100).round(2) \n",
    "\n",
    "# Picked from criteria pct>1. - HARDCODED, BUT ALSO CATEGORIES CHOSEN BY HAND\n",
    "meta = ['new','alternate','same','different','alternative',\n",
    "        'first','similar','above','previous','second','following']\n",
    "how_adj = ['direct','complete','full','constructive','bijective','combinatorial']\n",
    "what_adj = ['simple','short','detailed','elementary','simpler','rigorous','original','formal']\n",
    "\n",
    "a = count_adj.loc[meta].sum().to_frame(name = 'meta adjectives').transpose()\n",
    "b = count_adj.loc[how_adj].sum().to_frame(name = 'Obj. adjectives').transpose()\n",
    "c = count_adj.loc[what_adj].sum().to_frame(name = 'Subj. adjectives').transpose()\n",
    "adj_compund = a.append([b,c])\n",
    "\n",
    "# Saves both of them to /armchair folder as dataframes\n",
    "count_adj = count_adj.reset_index()\n",
    "adj_compund = adj_compund.reset_index()\n",
    "count_adj.to_feather(path+'/armchair/count_pct_adj_df'+timestr+'.feather')\n",
    "adj_compund.to_feather(path+'/armchair/count_pct_categorized_adj_df'+timestr+'.feather')\n",
    "# Saves both as tables in /tex folder\n",
    "count_adj.to_latex(path+'/tex/count_adjectives_freq'+timestr+'.tex')\n",
    "adj_compund.to_latex(path+'/tex/adjectives_classified_freq'+timestr+'.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is it proofs or figures/diagrams that provides understanding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load explanation_df\n",
    "LatestExplanationFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/explain_fullraw*'),key=os.path.getctime)\n",
    "explanation_df = pd.read_feather(LatestExplanationFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Times figure and proof are mentioned in explanation contexts\n",
    "figure_sent_df = sentence_extract(explanation_df, focuswords = ['figure','figures'],\n",
    "                                   contexts = None, remove_focuswords = False)\n",
    "proof_sent_df = sentence_extract(explanation_df, focuswords = ['proof','proofs'], \n",
    "                                    contexts = None, remove_focuswords = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_raw_df = word_extract(df_contexts,['figure']) # All the times figure is mentioned - in order to normalize\n",
    "proof_raw_df = word_extract(df_contexts,['proof'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now have everything we need - times proof/figure is mentioned in expla/understa contexts and how many times they are used in total. We can see it is more often authors uses a explanation word in regards to a proof than to a figure, but nothing is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_mention = len(figure_raw_df)\n",
    "proof_mention = len(proof_raw_df) # How many times proof and proofs are used - in order to normalize\n",
    "figure_explanation = len(figure_sent_df)\n",
    "proof_explanation = len(proof_sent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_understa_sent_df = sentence_extract(understa_raw_df, focuswords = ['proof','proofs'], \n",
    "                 contexts = None, remove_focuswords = False)\n",
    "figure_understa_sent_df = sentence_extract(understa_raw_df, focuswords = ['figure','figures'], \n",
    "                 contexts = None, remove_focuswords = False)\n",
    "figure_understand = len(figure_understa_sent_df)\n",
    "proof_understand = len(proof_understa_sent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation 0.2350031704992473\n"
     ]
    }
   ],
   "source": [
    "# Fisher exact test\n",
    "oddsratio, pvalue = stats.fisher_exact([[figure_explanation, figure_mention], [proof_explanation, proof_mention]])\n",
    "print('explanation',pvalue)\n",
    "#oddsratio, pvalue = stats.fisher_exact([[figure_understand, figure_mention], [proof_understand, proof_mention]])\n",
    "#print('understand',pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mainmathcat</th>\n",
       "      <th>context</th>\n",
       "      <th>sentence</th>\n",
       "      <th>focuswords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2009.04307</td>\n",
       "      <td>math.CV</td>\n",
       "      <td>outer</td>\n",
       "      <td>theorem  can be written as follows:\\n\\nthe following figures (figures  and ) explain numerically the result of proposition .</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2009.03215</td>\n",
       "      <td>math.AC</td>\n",
       "      <td>outer</td>\n",
       "      <td>this includes theorem a which relates the monomial-free restricted matching field ideals with the initial ideals of schubert varieties, theorems b and c which characterize the family of binomial, zero and non-binomial ideals and theorem  which is a non-inductive reformulation of theorem c. to explain these results clearly, we give examples and use figure  to give a visual representation of these results.</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2009.10024</td>\n",
       "      <td>math.CT</td>\n",
       "      <td>outer</td>\n",
       "      <td>figure 2: subbimodules of \\n\\n\\n\\n\\n\\n\\nin section , we explained how weakly exact structures give rise to bifunctors.</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2009.13916</td>\n",
       "      <td>math.NA</td>\n",
       "      <td>outer</td>\n",
       "      <td>an explanation comes from the analysis of the dynamic pattern representation vs the position within the dome-grid and the flux distribution, as provided in figure .</td>\n",
       "      <td>explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2009.09216</td>\n",
       "      <td>math.ST</td>\n",
       "      <td>outer</td>\n",
       "      <td>we represent these data on the complex plane in figure , using orange triangles for the low-speed wind values as explained above.</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2009.03233</td>\n",
       "      <td>math.DG</td>\n",
       "      <td>outer</td>\n",
       "      <td>we explain this in figure .</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2009.08251</td>\n",
       "      <td>math.OC</td>\n",
       "      <td>outer</td>\n",
       "      <td>we also choose for simplified explanation and throughout the figure consistent scaling was used.</td>\n",
       "      <td>explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2009.13127</td>\n",
       "      <td>math.CV</td>\n",
       "      <td>outer</td>\n",
       "      <td>we explain how the local dynamics near\\nthe singular set of we described above stitch together by studying\\nthe real-analytic foliation of the sphere induced by the\\nreal-time flow (figure ).</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>2009.02503</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>outer</td>\n",
       "      <td>the way to replace the vertices in should be clearly explained by figure .</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2009.13314</td>\n",
       "      <td>math.GT</td>\n",
       "      <td>outer</td>\n",
       "      <td>this is explained in detail in example  and illustrated in figure .</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>2009.12103</td>\n",
       "      <td>math.DS</td>\n",
       "      <td>outer</td>\n",
       "      <td>to get the kind lr-ul spiral whorl, we should think how to switch the connections in the figure  up side down, this can be happened if we use negative value of , we use in the system (&lt;ref&gt;) which is explained in example .</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>2009.07931</td>\n",
       "      <td>math.DS</td>\n",
       "      <td>outer</td>\n",
       "      <td>but as explained in  (and detailed below), we can decorate the \\ntiles to break down this symmetry by using a repetitive sequence of 's and 's (as shown in figure ).</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>2009.02495</td>\n",
       "      <td>math.PR</td>\n",
       "      <td>outer</td>\n",
       "      <td>let\\n\\nsince \\n is recurrent, we have a.s.\\nlet be the lifetime of , and define the event\\n\\n\\nwe explain next how is chosen (see figure ).</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>2009.05256</td>\n",
       "      <td>math.SG</td>\n",
       "      <td>outer</td>\n",
       "      <td>let us begin with considering a cartoon of a typical equator we wish to examine, in figure , and explain the motivation for the concrete construction which will follow in sections  and .</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>2009.14546</td>\n",
       "      <td>math.CA</td>\n",
       "      <td>outer</td>\n",
       "      <td>to explain the main ideas, consider the example of figure .</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>2009.14546</td>\n",
       "      <td>math.CA</td>\n",
       "      <td>outer</td>\n",
       "      <td>therefore the scaling behaviour of the flux falls into one of the following four different categories:\\n\\n\\n\\n\\n\\nin this paper we rule out “leak” fluxes by assumption, so that , with\\n\\n\\n\\n\\n\\n\\n\\n\\nlet us now explain these four categories in more detail by considering the example network of figure , which can now be redrawn as figure .</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>2009.12848</td>\n",
       "      <td>math.PR</td>\n",
       "      <td>outer</td>\n",
       "      <td>according to , if is an erdős-rényi random graph with edge probability , then it is s for all if and only if\\n \\n\\n\\n\\na visual inspection of figure  indicates that, as the planning horizon increases, can transition from sb to s. an informal explanation is the following.</td>\n",
       "      <td>explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>2009.13858</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>outer</td>\n",
       "      <td>in section  we explain in detail the cases of dimensions 3 and 4, providing figures which help the reader visualize the\\nmany properties of these polytopes.</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>2009.07369</td>\n",
       "      <td>math.SG</td>\n",
       "      <td>outer</td>\n",
       "      <td>this embedding sends to the form\\n\\n\\n\\nwhere and are given in figure  and will be explained shortly.</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>2009.04316</td>\n",
       "      <td>math.DS</td>\n",
       "      <td>outer</td>\n",
       "      <td>in figure hhbif, we choose and , which implies , and we indicate that the geometric mechanism described in section singgeom and section singpert1 can effectively explain the bifurcations of mmos that occur when the applied current is varied in the reduced three-timescale hodgkin-huxley model, equation ()hh_3ts.</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>2009.08839</td>\n",
       "      <td>math.IT</td>\n",
       "      <td>outer</td>\n",
       "      <td>however, as will be demonstrated shortly, this kind of explanation \\nis somewhat too simplistic when it comes to more refined figures of merit, like\\nthe error exponent and the source coding exponent.</td>\n",
       "      <td>explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>2009.07792</td>\n",
       "      <td>math.OC</td>\n",
       "      <td>proof</td>\n",
       "      <td>the idea is explained in figure .</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>2009.07792</td>\n",
       "      <td>math.OC</td>\n",
       "      <td>proof</td>\n",
       "      <td>then, as explained in figure , one can “rearrange” to create a with the same occupation measure but with doubly flexible points of different heights.</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>2009.07792</td>\n",
       "      <td>math.OC</td>\n",
       "      <td>proof</td>\n",
       "      <td>the first steps in the figure should be self-explanatory, but the final “flattening then ” step requires explanation.</td>\n",
       "      <td>explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>2009.02006</td>\n",
       "      <td>math.PR</td>\n",
       "      <td>proof</td>\n",
       "      <td>it is helpful to take a look at the graph of before explaining the geometry of the contours and we refer to figure .</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id mainmathcat context  \\\n",
       "115   2009.04307     math.CV   outer   \n",
       "146   2009.03215     math.AC   outer   \n",
       "161   2009.10024     math.CT   outer   \n",
       "207   2009.13916     math.NA   outer   \n",
       "212   2009.09216     math.ST   outer   \n",
       "288   2009.03233     math.DG   outer   \n",
       "354   2009.08251     math.OC   outer   \n",
       "368   2009.13127     math.CV   outer   \n",
       "411   2009.02503     math.CO   outer   \n",
       "570   2009.13314     math.GT   outer   \n",
       "781   2009.12103     math.DS   outer   \n",
       "914   2009.07931     math.DS   outer   \n",
       "1187  2009.02495     math.PR   outer   \n",
       "1231  2009.05256     math.SG   outer   \n",
       "1247  2009.14546     math.CA   outer   \n",
       "1248  2009.14546     math.CA   outer   \n",
       "1344  2009.12848     math.PR   outer   \n",
       "1517  2009.13858     math.CO   outer   \n",
       "1605  2009.07369     math.SG   outer   \n",
       "1638  2009.04316     math.DS   outer   \n",
       "1733  2009.08839     math.IT   outer   \n",
       "1776  2009.07792     math.OC   proof   \n",
       "1777  2009.07792     math.OC   proof   \n",
       "1778  2009.07792     math.OC   proof   \n",
       "1797  2009.02006     math.PR   proof   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                     sentence  \\\n",
       "115                                                                                                                                                                                                                                                                                              theorem  can be written as follows:\\n\\nthe following figures (figures  and ) explain numerically the result of proposition .   \n",
       "146   this includes theorem a which relates the monomial-free restricted matching field ideals with the initial ideals of schubert varieties, theorems b and c which characterize the family of binomial, zero and non-binomial ideals and theorem  which is a non-inductive reformulation of theorem c. to explain these results clearly, we give examples and use figure  to give a visual representation of these results.   \n",
       "161                                                                                                                                                                                                                                                                                                    figure 2: subbimodules of \\n\\n\\n\\n\\n\\n\\nin section , we explained how weakly exact structures give rise to bifunctors.   \n",
       "207                                                                                                                                                                                                                                                      an explanation comes from the analysis of the dynamic pattern representation vs the position within the dome-grid and the flux distribution, as provided in figure .   \n",
       "212                                                                                                                                                                                                                                                                                         we represent these data on the complex plane in figure , using orange triangles for the low-speed wind values as explained above.   \n",
       "288                                                                                                                                                                                                                                                                                                                                                                                               we explain this in figure .   \n",
       "354                                                                                                                                                                                                                                                                                                                          we also choose for simplified explanation and throughout the figure consistent scaling was used.   \n",
       "368                                                                                                                                                                                                                           we explain how the local dynamics near\\nthe singular set of we described above stitch together by studying\\nthe real-analytic foliation of the sphere induced by the\\nreal-time flow (figure ).   \n",
       "411                                                                                                                                                                                                                                                                                                                                                the way to replace the vertices in should be clearly explained by figure .   \n",
       "570                                                                                                                                                                                                                                                                                                                                                       this is explained in detail in example  and illustrated in figure .   \n",
       "781                                                                                                                                                                                            to get the kind lr-ul spiral whorl, we should think how to switch the connections in the figure  up side down, this can be happened if we use negative value of , we use in the system (<ref>) which is explained in example .   \n",
       "914                                                                                                                                                                                                                                                     but as explained in  (and detailed below), we can decorate the \\ntiles to break down this symmetry by using a repetitive sequence of 's and 's (as shown in figure ).   \n",
       "1187                                                                                                                                                                                                                                                                              let\\n\\nsince \\n is recurrent, we have a.s.\\nlet be the lifetime of , and define the event\\n\\n\\nwe explain next how is chosen (see figure ).   \n",
       "1231                                                                                                                                                                                                                               let us begin with considering a cartoon of a typical equator we wish to examine, in figure , and explain the motivation for the concrete construction which will follow in sections  and .   \n",
       "1247                                                                                                                                                                                                                                                                                                                                                              to explain the main ideas, consider the example of figure .   \n",
       "1248                                                                     therefore the scaling behaviour of the flux falls into one of the following four different categories:\\n\\n\\n\\n\\n\\nin this paper we rule out “leak” fluxes by assumption, so that , with\\n\\n\\n\\n\\n\\n\\n\\n\\nlet us now explain these four categories in more detail by considering the example network of figure , which can now be redrawn as figure .   \n",
       "1344                                                                                                                                          according to , if is an erdős-rényi random graph with edge probability , then it is s for all if and only if\\n \\n\\n\\n\\na visual inspection of figure  indicates that, as the planning horizon increases, can transition from sb to s. an informal explanation is the following.   \n",
       "1517                                                                                                                                                                                                                                                             in section  we explain in detail the cases of dimensions 3 and 4, providing figures which help the reader visualize the\\nmany properties of these polytopes.   \n",
       "1605                                                                                                                                                                                                                                                                                                                    this embedding sends to the form\\n\\n\\n\\nwhere and are given in figure  and will be explained shortly.   \n",
       "1638                                                                                                 in figure hhbif, we choose and , which implies , and we indicate that the geometric mechanism described in section singgeom and section singpert1 can effectively explain the bifurcations of mmos that occur when the applied current is varied in the reduced three-timescale hodgkin-huxley model, equation ()hh_3ts.   \n",
       "1733                                                                                                                                                                                                                 however, as will be demonstrated shortly, this kind of explanation \\nis somewhat too simplistic when it comes to more refined figures of merit, like\\nthe error exponent and the source coding exponent.   \n",
       "1776                                                                                                                                                                                                                                                                                                                                                                                        the idea is explained in figure .   \n",
       "1777                                                                                                                                                                                                                                                                    then, as explained in figure , one can “rearrange” to create a with the same occupation measure but with doubly flexible points of different heights.   \n",
       "1778                                                                                                                                                                                                                                                                                                    the first steps in the figure should be self-explanatory, but the final “flattening then ” step requires explanation.   \n",
       "1797                                                                                                                                                                                                                                                                                                     it is helpful to take a look at the graph of before explaining the geometry of the contours and we refer to figure .   \n",
       "\n",
       "       focuswords  \n",
       "115       explain  \n",
       "146       explain  \n",
       "161       explain  \n",
       "207   explanation  \n",
       "212       explain  \n",
       "288       explain  \n",
       "354   explanation  \n",
       "368       explain  \n",
       "411       explain  \n",
       "570       explain  \n",
       "781       explain  \n",
       "914       explain  \n",
       "1187      explain  \n",
       "1231      explain  \n",
       "1247      explain  \n",
       "1248      explain  \n",
       "1344  explanation  \n",
       "1517      explain  \n",
       "1605      explain  \n",
       "1638      explain  \n",
       "1733  explanation  \n",
       "1776      explain  \n",
       "1777      explain  \n",
       "1778  explanation  \n",
       "1797      explain  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "np.random.seed(42)\n",
    "figure_sent_df#.sample(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure_raw_df = figure_raw_df.reset_index()\n",
    "#sentence_extract(proof_raw_df, focuswords = ['illustrate','illustrates','illustrating','illustrated'],\n",
    "#                                   contexts = None, remove_focuswords = False)\n",
    "obvious_raw_df = word_extract(df_contexts,['obvious'])\n",
    "obvious_freq_df = freq_wordcount_branch(obvious_raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of Obvious - Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mainmathcat</th>\n",
       "      <th>focuswords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>math.MG</td>\n",
       "      <td>83.690412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>math.PR</td>\n",
       "      <td>93.221894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>math.AP</td>\n",
       "      <td>94.814024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>math.GT</td>\n",
       "      <td>95.132317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>math.NA</td>\n",
       "      <td>95.837193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>math.OC</td>\n",
       "      <td>111.919972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>math.RT</td>\n",
       "      <td>112.144805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>math.HO</td>\n",
       "      <td>112.585847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>math.ST</td>\n",
       "      <td>113.373482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>math.DS</td>\n",
       "      <td>116.093658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>math.DG</td>\n",
       "      <td>120.431016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>math.QA</td>\n",
       "      <td>129.675810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>math.CA</td>\n",
       "      <td>144.656900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>math.IT</td>\n",
       "      <td>150.453354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>math.SG</td>\n",
       "      <td>152.724218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>math.MP</td>\n",
       "      <td>155.677299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>math.CO</td>\n",
       "      <td>157.234180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>math.KT</td>\n",
       "      <td>170.627288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>math.GM</td>\n",
       "      <td>177.602368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>math.AC</td>\n",
       "      <td>177.872643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>math.NT</td>\n",
       "      <td>179.948796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>math.GR</td>\n",
       "      <td>203.056737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>math.CV</td>\n",
       "      <td>206.631323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>math.RA</td>\n",
       "      <td>211.704219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>math.FA</td>\n",
       "      <td>227.936723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>math.AG</td>\n",
       "      <td>230.161113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>math.AT</td>\n",
       "      <td>252.360903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>math.OA</td>\n",
       "      <td>263.251226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>math.LO</td>\n",
       "      <td>263.483320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>math.SP</td>\n",
       "      <td>271.987255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>math.CT</td>\n",
       "      <td>311.212124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>math.GN</td>\n",
       "      <td>315.509342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mainmathcat  focuswords\n",
       "17     math.MG   83.690412\n",
       "0      math.PR   93.221894\n",
       "4      math.AP   94.814024\n",
       "10     math.GT   95.132317\n",
       "25     math.NA   95.837193\n",
       "1      math.OC  111.919972\n",
       "7      math.RT  112.144805\n",
       "11     math.HO  112.585847\n",
       "2      math.ST  113.373482\n",
       "12     math.DS  116.093658\n",
       "15     math.DG  120.431016\n",
       "28     math.QA  129.675810\n",
       "5      math.CA  144.656900\n",
       "13     math.IT  150.453354\n",
       "30     math.SG  152.724218\n",
       "8      math.MP  155.677299\n",
       "9      math.CO  157.234180\n",
       "29     math.KT  170.627288\n",
       "31     math.GM  177.602368\n",
       "6      math.AC  177.872643\n",
       "3      math.NT  179.948796\n",
       "16     math.GR  203.056737\n",
       "14     math.CV  206.631323\n",
       "21     math.RA  211.704219\n",
       "23     math.FA  227.936723\n",
       "18     math.AG  230.161113\n",
       "26     math.AT  252.360903\n",
       "20     math.OA  263.251226\n",
       "22     math.LO  263.483320\n",
       "27     math.SP  271.987255\n",
       "24     math.CT  311.212124\n",
       "19     math.GN  315.509342"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obvious_raw_df = word_extract(df_contexts,['obvious'])\n",
    "obvious_freq_df = freq_wordcount_branch(obvious_raw_df)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "obvious_freq_df.sort_values('focuswords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = adj_nouns(explanation_df,contexts = ['outer','meta','other','proof','theorem'],focus_noun = ['explanation','explanations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjective</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>detailed</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>further</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brief</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>possible</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geometric</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satisfactory</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intuitive</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alternative</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heuristic</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complete</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagrammatic</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>such</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differential</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precise</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numerical</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inadequate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supplementary</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pictorial</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visual</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>certain</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mathematical</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theoretical</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conceptual</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extended</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>informal</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clear</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>underlying</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilistic</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualitative</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transparent</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thorough</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simplified</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsequent</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reasonable</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ultimate</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additional</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>own</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intrinsic</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count\n",
       "adjective           \n",
       "detailed          19\n",
       "further            9\n",
       "more               8\n",
       "brief              8\n",
       "simple             5\n",
       "possible           5\n",
       "geometric          4\n",
       "satisfactory       4\n",
       "intuitive          3\n",
       "alternative        3\n",
       "heuristic          3\n",
       "complete           2\n",
       "partial            2\n",
       "natural            2\n",
       "diagrammatic       2\n",
       "such               1\n",
       "good               1\n",
       "differential       1\n",
       "precise            1\n",
       "previous           1\n",
       "numerical          1\n",
       "inadequate         1\n",
       "supplementary      1\n",
       "pictorial          1\n",
       "visual             1\n",
       "certain            1\n",
       "helpful            1\n",
       "mathematical       1\n",
       "extra              1\n",
       "theoretical        1\n",
       "conceptual         1\n",
       "extended           1\n",
       "informal           1\n",
       "clear              1\n",
       "underlying         1\n",
       "general            1\n",
       "probabilistic      1\n",
       "qualitative        1\n",
       "transparent        1\n",
       "thorough           1\n",
       "physical           1\n",
       "simplified         1\n",
       "subsequent         1\n",
       "reasonable         1\n",
       "ultimate           1\n",
       "additional         1\n",
       "own                1\n",
       "best               1\n",
       "intrinsic          1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_adj = test['adjective'].value_counts().to_frame()\n",
    "test_adj.index.name = 'adjective'\n",
    "test_adj = test_adj.rename(columns={'adjective': 'count'})\n",
    "test_adj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
