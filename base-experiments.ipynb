{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import dataframe_image as dfi\n",
    "path = '/Users/Svesketerning/Google-Drev/experiments'\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for counts over mainmath, context and mainmath and context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_wordcount_context(focusword_df):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    values_context = []\n",
    "    for j in contexts:\n",
    "        values_context.append(len(focusword_df.loc[(focusword_df['context'] == j)]))\n",
    "    result.append({'outer': values_context[0],'theorem': values_context[1],\n",
    "                       'meta': values_context[2], 'proof': values_context[3], 'other': values_context[4]})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    return df\n",
    "def freq_wordcount_context(focusword_df):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    values_context = []\n",
    "    for j in contexts:\n",
    "        a = len(focusword_df.loc[(focusword_df['context'] == j)])\n",
    "        b = df_arxiv[j].sum()\n",
    "        if b>0:\n",
    "            values_context.append(a/b * 10**6)\n",
    "        else:\n",
    "            values_context.append(None)\n",
    "    result.append({'outer': values_context[0],'theorem': values_context[1],\n",
    "                   'meta': values_context[2], 'proof': values_context[3], 'other': values_context[4]})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_wordcount_branch(focusword_df):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    for i in focusword_df['mainmathcat'].unique():\n",
    "        a =len(focusword_df.loc[(focusword_df['mainmathcat'] == i)])\n",
    "        result.append({'mainmathcat': i, 'focuswords': a})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    return df\n",
    "def freq_wordcount_branch(focusword_df):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    for i in focusword_df['mainmathcat'].unique():\n",
    "        values_context = []\n",
    "        a = len(focusword_df.loc[(focusword_df['mainmathcat'] == i)])\n",
    "        b = df_arxiv.loc[(df_arxiv['mainmathcat'] == i)][['outer','theorem','meta',\n",
    "                                                               'proof','other']].sum().sum()\n",
    "        if b>0:\n",
    "            c = a/b * 10**6\n",
    "        else:\n",
    "            c = None\n",
    "        result.append({'mainmathcat': i, 'focuswords': c})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context & Branch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the raw focusword count based on context and branch\n",
    "def raw_wordcount(focusword_df):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    for i in focusword_df['mainmathcat'].unique():\n",
    "        values_context = []\n",
    "        for j in contexts:\n",
    "            values_context.append(len(focusword_df.loc[(focusword_df['mainmathcat'] == i) \n",
    "                                                       & (focusword_df['context'] == j)]))\n",
    "        result.append({'mainmathcat':i, 'outer': values_context[0],'theorem': values_context[1],\n",
    "                       'meta': values_context[2], 'proof': values_context[3], 'other': values_context[4]})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=['mainmathcat']) for i in range(len(result))])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    df = df.append(df.sum(numeric_only=True), ignore_index=True)\n",
    "    return df\n",
    "# Counts the frequency (per million word) of focusword based on context and branch\n",
    "def freq_wordcount(focusword_df):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    for i in focusword_df['mainmathcat'].unique():\n",
    "        values_context = []\n",
    "        for j in contexts:\n",
    "            a = len(focusword_df.loc[(focusword_df['mainmathcat'] == i) \n",
    "                                     & (focusword_df['context'] == j)])\n",
    "            b = df_arxiv.loc[(df_arxiv['mainmathcat'] == i)][j].sum()\n",
    "            if b>0:\n",
    "                values_context.append(a/b * 10**6)\n",
    "            else:\n",
    "                values_context.append(None)\n",
    "        result.append({'mainmathcat':i, 'outer': values_context[0],'theorem': values_context[1],\n",
    "                       'meta': values_context[2], 'proof': values_context[3], 'other': values_context[4]})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=['mainmathcat']) for i in range(len(result))])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    total_freq = []\n",
    "    freq_dict = []\n",
    "    for j in contexts:\n",
    "        a = len(explanation_df.loc[(explanation_df['context'] == j)])/df_arxiv[j].sum()* 10**6\n",
    "        total_freq.append(a)\n",
    "    freq_dict.append({'mainmathcat':'Total Freq.', 'outer': total_freq[0],'theorem': total_freq[1],\n",
    "                      'meta': total_freq[2], 'proof': total_freq[3], 'other': total_freq[4]})\n",
    "    df = df.append(freq_dict, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation base data, dataframes and Latex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LatestDatabaseFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/arxiv_extended_database*'),key=os.path.getctime)\n",
    "df_arxiv = pd.read_feather(LatestDatabaseFile)\n",
    "\n",
    "LatestExplanationFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/explain_fullraw*'),key=os.path.getctime)\n",
    "explanation_df = pd.read_feather(LatestExplanationFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves 6 files and 6 Latex tables \n",
    "\n",
    "explain_contextbranch_raw = raw_wordcount(explanation_df)\n",
    "explain_contextbranch_raw.to_feather(path+'/explanation-data/explain_contextbranch_raw'+timestr+'.feather')\n",
    "explain_contextbranch_raw.to_latex(path+'/tex/explain_contextbranch_raw'+timestr+'.tex')\n",
    "\n",
    "explain_context_raw = raw_wordcount_context(explanation_df)\n",
    "explain_context_raw.to_feather(path+'/explanation-data/explain_context_raw'+timestr+'.feather')\n",
    "explain_context_raw.to_latex(path+'/tex/explain_context_raw'+timestr+'.tex')\n",
    "\n",
    "explain_branch_raw = raw_wordcount_branch(explanation_df)\n",
    "explain_branch_raw.to_feather(path+'/explanation-data/explain_branch_raw'+timestr+'.feather')\n",
    "explain_branch_raw.to_latex(path+'/tex/explain_branch_raw'+timestr+'.tex')\n",
    "\n",
    "explain_contextbranch_freq = freq_wordcount(explanation_df)\n",
    "explain_contextbranch_freq.to_feather(path+'/explanation-data/explain_contextbranch_freq'+timestr+'.feather')\n",
    "explain_contextbranch_freq.to_latex(path+'/tex/explain_contextbranch_freq'+timestr+'.tex')\n",
    "\n",
    "explain_context_freq = freq_wordcount_context(explanation_df)\n",
    "explain_context_freq.to_feather(path+'/explanation-data/explain_context_freq'+timestr+'.feather')\n",
    "explain_context_freq.to_latex(path+'/tex/explain_context_freq'+timestr+'.tex')\n",
    "\n",
    "explain_branch_freq = freq_wordcount_branch(explanation_df)\n",
    "explain_branch_freq.to_feather(path+'/explanation-data/explain_branch_freq'+timestr+'.feather')\n",
    "explain_branch_freq.to_latex(path+'/tex/explain_branch_freq'+timestr+'.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Better context table with total and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_context_freq_total = pd.concat([raw_wordcount_context(explanation_df), \n",
    "            freq_wordcount_context(explanation_df)])\n",
    "explain_context_freq_total.insert(0, 'method',['Total','Frequency'])\n",
    "explain_context_freq_total = explain_context_freq_total.set_index('method').round(2)\n",
    "explain_context_freq_total.to_latex(path+'/tex/explain_context_count_and_freq'+timestr+'.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### p-values across all branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LatestExplanationContextBranchRawFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/explanation-data/explain_contextbranch_raw*'),key=os.path.getctime)\n",
    "explain_contextbranch_raw = pd.read_feather(LatestExplanationContextBranchRawFile)\n",
    "\n",
    "LatestExplanationBranchRawFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/explanation-data/explain_branch_raw*'),key=os.path.getctime)\n",
    "explain_branch_raw = pd.read_feather(LatestExplanationBranchRawFile)\n",
    "explain_branch_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting words in each branch, sourced from above functions\n",
    "contexts = ['outer','theorem', 'meta', 'proof', 'other']\n",
    "result = []\n",
    "for i in explanation_df['mainmathcat'].unique():\n",
    "    branch_count = 0\n",
    "    for j in contexts:\n",
    "        branch_count += df_arxiv.loc[(df_arxiv['mainmathcat'] == i)][j].sum()\n",
    "    result.append({'mainmathcat': i, 'count': branch_count})\n",
    "branch_count_df = pd.concat([pd.DataFrame(result[i], index=['mainmathcat']) for i in range(len(result))])\n",
    "branch_count_df \n",
    "explain_branch_raw\n",
    "branch_merged_df = pd.merge(explain_branch_raw,branch_count_df, on = ['mainmathcat'])\n",
    "result = []\n",
    "for i in branch_merged_df['mainmathcat'].unique():\n",
    "    a = [branch_merged_df[branch_merged_df['mainmathcat'] == i]['focuswords'].item(),\n",
    "             branch_merged_df[branch_merged_df['mainmathcat'] == i]['count'].item()]\n",
    "    pvalues = []\n",
    "    for j in branch_merged_df['mainmathcat'].unique():\n",
    "        b = [branch_merged_df[branch_merged_df['mainmathcat'] == j]['focuswords'].item(),\n",
    "             branch_merged_df[branch_merged_df['mainmathcat'] == j]['count'].item()]\n",
    "        oddsratio, pvalue = stats.fisher_exact([a,b])\n",
    "        pvalues.append(pvalue)\n",
    "    result.append(pvalues)\n",
    "    \n",
    "# Saves p-value thingy as png \n",
    "pvalues_df = pd.DataFrame(result,\n",
    "             columns = branch_merged_df['mainmathcat'].unique().tolist(),\n",
    "             index = branch_merged_df['mainmathcat'].unique().tolist()) \n",
    "pvalues_df = pvalues_df.style.applymap(lambda x: 'color: red' if x <= 0.05 and x <=5 else 'color: black')\n",
    "dfi.export(pvalues_df, path+'/figures/pvalues_df.png',max_cols = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
