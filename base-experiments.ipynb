{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import dataframe_image as dfi\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "path = '/Users/Svesketerning/Google-Drev/experiments'\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for counts over mainmath, context and mainmath and context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_wordcount_context(focusword_df):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    values_context = []\n",
    "    for j in contexts:\n",
    "        values_context.append(len(focusword_df.loc[(focusword_df['context'] == j)]))\n",
    "    result.append({'outer': values_context[0],'theorem': values_context[1],\n",
    "                       'meta': values_context[2], 'proof': values_context[3], 'other': values_context[4]})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    return df\n",
    "def freq_wordcount_context(focusword_df):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    values_context = []\n",
    "    for j in contexts:\n",
    "        a = len(focusword_df.loc[(focusword_df['context'] == j)])\n",
    "        b = df_arxiv[j].sum()\n",
    "        if b>0:\n",
    "            values_context.append(a/b * 10**6)\n",
    "        else:\n",
    "            values_context.append(None)\n",
    "    result.append({'outer': values_context[0],'theorem': values_context[1],\n",
    "                   'meta': values_context[2], 'proof': values_context[3], 'other': values_context[4]})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_wordcount_branch(focusword_df):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    for i in focusword_df['mainmathcat'].unique():\n",
    "        a =len(focusword_df.loc[(focusword_df['mainmathcat'] == i)])\n",
    "        result.append({'mainmathcat': i, 'focuswords': a})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    return df\n",
    "def freq_wordcount_branch(focusword_df,df_arxiv):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    for i in focusword_df['mainmathcat'].unique():\n",
    "        values_context = []\n",
    "        a = len(focusword_df.loc[(focusword_df['mainmathcat'] == i)])\n",
    "        b = df_arxiv.loc[(df_arxiv['mainmathcat'] == i)][['outer','theorem','meta',\n",
    "                                                               'proof','other']].sum().sum()\n",
    "        if b>0:\n",
    "            c = a/b * 10**6\n",
    "        else:\n",
    "            c = None\n",
    "        result.append({'mainmathcat': i, 'focuswords': c})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=[0]) for i in range(len(result))])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context & Branch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the raw focusword count based on context and branch\n",
    "def raw_wordcount(focusword_df,df_arxiv):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    for i in focusword_df['mainmathcat'].unique():\n",
    "        values_context = []\n",
    "        for j in contexts:\n",
    "            values_context.append(len(focusword_df.loc[(focusword_df['mainmathcat'] == i) \n",
    "                                                       & (focusword_df['context'] == j)]))\n",
    "        result.append({'mainmathcat':i, 'outer': values_context[0],'theorem': values_context[1],\n",
    "                       'meta': values_context[2], 'proof': values_context[3], 'other': values_context[4]})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=['mainmathcat']) for i in range(len(result))])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    df = df.append(df.sum(numeric_only=True), ignore_index=True)\n",
    "    return df\n",
    "# Counts the frequency (per million word) of focusword based on context and branch\n",
    "def freq_wordcount(focusword_df,df_arxiv):\n",
    "    result = []\n",
    "    contexts = ['outer','theorem', 'meta', 'proof', 'other'] # Non functional!\n",
    "    for i in focusword_df['mainmathcat'].unique():\n",
    "        values_context = []\n",
    "        for j in contexts:\n",
    "            a = len(focusword_df.loc[(focusword_df['mainmathcat'] == i) \n",
    "                                     & (focusword_df['context'] == j)])\n",
    "            b = df_arxiv.loc[(df_arxiv['mainmathcat'] == i)][j].sum()\n",
    "            if b>0:\n",
    "                values_context.append(a/b * 10**6)\n",
    "            else:\n",
    "                values_context.append(None)\n",
    "        result.append({'mainmathcat':i, 'outer': values_context[0],'theorem': values_context[1],\n",
    "                       'meta': values_context[2], 'proof': values_context[3], 'other': values_context[4]})\n",
    "    df = pd.concat([pd.DataFrame(result[i], index=['mainmathcat']) for i in range(len(result))])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis = 1)\n",
    "    total_freq = []\n",
    "    freq_dict = []\n",
    "    for j in contexts:\n",
    "        a = len(focusword_df.loc[(focusword_df['context'] == j)])/df_arxiv[j].sum()* 10**6\n",
    "        total_freq.append(a)\n",
    "    freq_dict.append({'mainmathcat':'Total Freq.', 'outer': total_freq[0],'theorem': total_freq[1],\n",
    "                      'meta': total_freq[2], 'proof': total_freq[3], 'other': total_freq[4]})\n",
    "    df = df.append(freq_dict, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation base data, dataframes and Latex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "LatestDatabaseFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/arxiv_extended_database*'),key=os.path.getctime)\n",
    "df_arxiv = pd.read_feather(LatestDatabaseFile)\n",
    "\n",
    "LatestExplanationFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/explain_fullraw*'),key=os.path.getctime)\n",
    "explanation_df = pd.read_feather(LatestExplanationFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves 6 files and 6 Latex tables \n",
    "\n",
    "explain_contextbranch_raw = raw_wordcount(explanation_df)\n",
    "explain_contextbranch_raw.to_feather(path+'/explanation-data/explain_contextbranch_raw'+timestr+'.feather')\n",
    "# Nicer in TeX\n",
    "explain_contextbranch_raw[['outer', 'theorem', 'meta', 'proof', 'other']] = explain_contextbranch_raw[['outer', 'theorem', 'meta', 'proof', 'other']].astype(int)\n",
    "explain_contextbranch_raw.loc[32,'mainmathcat'] = 'Total'\n",
    "explain_contextbranch_raw.to_latex(path+'/tex/explain_contextbranch_raw'+timestr+'.tex', index = False)\n",
    "\n",
    "explain_context_raw = raw_wordcount_context(explanation_df)\n",
    "explain_context_raw.to_feather(path+'/explanation-data/explain_context_raw'+timestr+'.feather')\n",
    "explain_context_raw.to_latex(path+'/tex/explain_context_raw'+timestr+'.tex')\n",
    "\n",
    "explain_branch_raw = raw_wordcount_branch(explanation_df)\n",
    "explain_branch_raw.to_feather(path+'/explanation-data/explain_branch_raw'+timestr+'.feather')\n",
    "explain_branch_raw.to_latex(path+'/tex/explain_branch_raw'+timestr+'.tex')\n",
    "\n",
    "explain_contextbranch_freq = freq_wordcount(explanation_df)\n",
    "explain_contextbranch_freq.to_feather(path+'/explanation-data/explain_contextbranch_freq'+timestr+'.feather')\n",
    "explain_contextbranch_freq.to_latex(path+'/tex/explain_contextbranch_freq'+timestr+'.tex')\n",
    "\n",
    "explain_context_freq = freq_wordcount_context(explanation_df)\n",
    "explain_context_freq.to_feather(path+'/explanation-data/explain_context_freq'+timestr+'.feather')\n",
    "explain_context_freq.to_latex(path+'/tex/explain_context_freq'+timestr+'.tex')\n",
    "\n",
    "explain_branch_freq = freq_wordcount_branch(explanation_df)\n",
    "explain_branch_freq.to_feather(path+'/explanation-data/explain_branch_freq'+timestr+'.feather')\n",
    "explain_branch_freq.to_latex(path+'/tex/explain_branch_freq'+timestr+'.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Better context table with total and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_context_freq_total = pd.concat([raw_wordcount_context(explanation_df), \n",
    "            freq_wordcount_context(explanation_df)])\n",
    "explain_context_freq_total.insert(0, 'method',['Total','Frequency'])\n",
    "explain_context_freq_total = explain_context_freq_total.set_index('method').round(2)\n",
    "explain_context_freq_total.to_latex(path+'/tex/explain_context_count_and_freq'+timestr+'.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### p-values across all branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LatestExplanationContextBranchRawFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/explanation-data/explain_contextbranch_raw*'),key=os.path.getctime)\n",
    "explain_contextbranch_raw = pd.read_feather(LatestExplanationContextBranchRawFile)\n",
    "\n",
    "LatestExplanationBranchRawFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/explanation-data/explain_branch_raw*'),key=os.path.getctime)\n",
    "explain_branch_raw = pd.read_feather(LatestExplanationBranchRawFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting words in each branch, sourced from above functions\n",
    "contexts = ['outer','theorem', 'meta', 'proof', 'other']\n",
    "result = []\n",
    "for i in explanation_df['mainmathcat'].unique():\n",
    "    branch_count = 0\n",
    "    for j in contexts:\n",
    "        branch_count += df_arxiv.loc[(df_arxiv['mainmathcat'] == i)][j].sum()\n",
    "    result.append({'mainmathcat': i, 'count': branch_count})\n",
    "branch_count_df = pd.concat([pd.DataFrame(result[i], index=['mainmathcat']) for i in range(len(result))])\n",
    "branch_count_df \n",
    "explain_branch_raw\n",
    "branch_merged_df = pd.merge(explain_branch_raw,branch_count_df, on = ['mainmathcat'])\n",
    "result = []\n",
    "for i in branch_merged_df['mainmathcat'].unique():\n",
    "    a = [branch_merged_df[branch_merged_df['mainmathcat'] == i]['focuswords'].item(),\n",
    "             branch_merged_df[branch_merged_df['mainmathcat'] == i]['count'].item()\n",
    "         -branch_merged_df[branch_merged_df['mainmathcat'] == i]['focuswords'].item()]\n",
    "    pvalues = []\n",
    "    for j in branch_merged_df['mainmathcat'].unique():\n",
    "        b = [branch_merged_df[branch_merged_df['mainmathcat'] == j]['focuswords'].item(),\n",
    "             branch_merged_df[branch_merged_df['mainmathcat'] == j]['count'].item()\n",
    "            -branch_merged_df[branch_merged_df['mainmathcat'] == j]['focuswords'].item()]\n",
    "        chi2, pvalue, dof, ex = stats.chi2_contingency([a,b], correction=False, lambda_=\"log-likelihood\")\n",
    "        pvalues.append(pvalue)\n",
    "    result.append(pvalues)\n",
    "    \n",
    "# Saves p-value thingy as png \n",
    "pvalues_df = pd.DataFrame(result,\n",
    "             columns = branch_merged_df['mainmathcat'].unique().tolist(),\n",
    "             index = branch_merged_df['mainmathcat'].unique().tolist()) \n",
    "pvalues_df = pvalues_df.round(4)\n",
    "pvaluesred_df = pvalues_df.style.applymap(lambda x: 'color: red' if x <= 0.05 and x <=5 else 'color: black')\n",
    "dfi.export(pvaluesred_df, path+'/figures/pvalues_df.png',max_cols = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_jon_categories = [['math.NT'],['math.CT'],['math.AG'],['math.CO'],['math.CV'],\n",
    "                       ['math.MP'],['math.PR'],['math.AP','math.CA','math.DS','math.SG'],\n",
    "                       ['math.KT','math.GT','math.AT'],['math.HO','math.GM'],\n",
    "                       ['math.OC','math.IT', 'math.NA','math.ST'],\n",
    "                       ['math.OC','math.IT', 'math.NA','math.ST','math.MP'],\n",
    "                       ['math.MG','math.DG'],['math.FA','math.SP','math.OA'],\n",
    "                       ['math.GN','math.LO'],['math.RT','math.GR','math.RA','math.AC','math.QA']]\n",
    "for i in alex_jon_categories[7:]:\n",
    "    df = pvalues_df[i].loc[i]\n",
    "    df.to_latex(path+'/tex/pvalue'+str(i)+timestr+'.tex')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math.AT</th>\n",
       "      <th>math.CT</th>\n",
       "      <th>math.DS</th>\n",
       "      <th>math.FA</th>\n",
       "      <th>math.PR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>math.AT</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math.CT</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math.DS</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math.FA</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math.PR</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         math.AT  math.CT  math.DS  math.FA  math.PR\n",
       "math.AT   1.0000   0.0009   0.0000      0.0    0.000\n",
       "math.CT   0.0009   1.0000   0.0158      0.0    0.694\n",
       "math.DS   0.0000   0.0158   1.0000      0.0    0.000\n",
       "math.FA   0.0000   0.0000   0.0000      1.0    0.000\n",
       "math.PR   0.0000   0.6940   0.0000      0.0    1.000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_cat = ['math.AT','math.CT','math.DS','math.FA','math.PR']\n",
    "df = pvalues_df[quali_cat].loc[quant_cat]\n",
    "df.to_latex(path+'/tex/pvalue'+str(quant_cat)+timestr+'.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ramos Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LatestRamosExplanationFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/explain_ramos_fullraw*'),key=os.path.getctime)\n",
    "ramos_explanation_df = pd.read_feather(LatestRamosExplanationFile)\n",
    "\n",
    "LatestRamosFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/ramos2009a_arxiv_contexts*'),key=os.path.getctime)\n",
    "df_ramos_contexts = pd.read_feather(LatestRamosFile)\n",
    "\n",
    "LatestRamosDatabaseFile = max(glob.iglob('/Users/Svesketerning/Google-Drev/experiments/database-files/ramos2009a_arxiv_extended_database*'),key=os.path.getctime)\n",
    "df_arxiv_ramos = pd.read_feather(LatestRamosDatabaseFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramos_explain_branch_raw = raw_wordcount_branch(ramos_explanation_df)\n",
    "ramos_explain_branch_raw.to_feather(path+'/explanation-data/ramos_explain_branch_raw'+timestr+'.feather')\n",
    "ramos_explain_branch_raw.to_latex(path+'/tex/ramos_explain_branch_raw'+timestr+'.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Not super well documented code to test specific p-values, e.g. using the Pease et al. key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64098066\n"
     ]
    }
   ],
   "source": [
    "contexts = ['outer','theorem', 'meta', 'proof', 'other']\n",
    "result = []\n",
    "for j in contexts:\n",
    "    branch_count = 0\n",
    "    for i in explanation_df['mainmathcat'].unique():\n",
    "        branch_count += df_arxiv_ramos.loc[(df_arxiv_ramos['mainmathcat'] == i)][j].sum()\n",
    "    result.append({'context': j, 'count': branch_count})\n",
    "result\n",
    "print(43162407+4089833+2442936+10369089+4033801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j = ['math.HO','math.GM']\n",
    "\n",
    "a = [branch_merged_df[branch_merged_df['mainmathcat'] == i]['focuswords'].item(),\n",
    "     branch_merged_df[branch_merged_df['mainmathcat'] == i]['count'].item()\n",
    "     -branch_merged_df[branch_merged_df['mainmathcat'] == i]['focuswords'].item()]\n",
    "\n",
    "b = [branch_merged_df[branch_merged_df['mainmathcat'] == j]['focuswords'].item(),\n",
    "     branch_merged_df[branch_merged_df['mainmathcat'] == j]['count'].item()\n",
    "     -branch_merged_df[branch_merged_df['mainmathcat'] == j]['focuswords'].item()]\n",
    "    \n",
    "cont_tbl = [a,b]\n",
    "t22 = sm.stats.Table2x2(cont_tbl)\n",
    "print(t22.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mainmathcat</th>\n",
       "      <th>maincat</th>\n",
       "      <th>outer</th>\n",
       "      <th>theorem</th>\n",
       "      <th>meta</th>\n",
       "      <th>proof</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0901.0015</td>\n",
       "      <td>math.IT</td>\n",
       "      <td>math.IT</td>\n",
       "      <td>2140</td>\n",
       "      <td>585</td>\n",
       "      <td>305</td>\n",
       "      <td>706</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0901.0019</td>\n",
       "      <td>math.DG</td>\n",
       "      <td>math.DG</td>\n",
       "      <td>5105</td>\n",
       "      <td>109</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0901.0020</td>\n",
       "      <td>math.QA</td>\n",
       "      <td>math.QA</td>\n",
       "      <td>9037</td>\n",
       "      <td>496</td>\n",
       "      <td>150</td>\n",
       "      <td>334</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0901.0021</td>\n",
       "      <td>math.AG</td>\n",
       "      <td>math.AG</td>\n",
       "      <td>2299</td>\n",
       "      <td>225</td>\n",
       "      <td>26</td>\n",
       "      <td>1860</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0901.0022</td>\n",
       "      <td>math.AP</td>\n",
       "      <td>math.AP</td>\n",
       "      <td>5212</td>\n",
       "      <td>436</td>\n",
       "      <td>16</td>\n",
       "      <td>618</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9681</th>\n",
       "      <td>0908.2751</td>\n",
       "      <td>math.RA</td>\n",
       "      <td>math.RA</td>\n",
       "      <td>4861</td>\n",
       "      <td>683</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9682</th>\n",
       "      <td>0908.2942</td>\n",
       "      <td>math.AP</td>\n",
       "      <td>math.AP</td>\n",
       "      <td>7214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9683</th>\n",
       "      <td>0908.3174</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>2696</td>\n",
       "      <td>391</td>\n",
       "      <td>636</td>\n",
       "      <td>1012</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9684</th>\n",
       "      <td>0908.3636</td>\n",
       "      <td>math.NA</td>\n",
       "      <td>math.NA</td>\n",
       "      <td>1433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>0908.4482</td>\n",
       "      <td>math.AG</td>\n",
       "      <td>math.AG</td>\n",
       "      <td>1940</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9686 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id mainmathcat  maincat  outer  theorem  meta  proof  other\n",
       "0     0901.0015     math.IT  math.IT   2140      585   305    706    125\n",
       "1     0901.0019     math.DG  math.DG   5105      109    33     36    127\n",
       "2     0901.0020     math.QA  math.QA   9037      496   150    334    292\n",
       "3     0901.0021     math.AG  math.AG   2299      225    26   1860     56\n",
       "4     0901.0022     math.AP  math.AP   5212      436    16    618     66\n",
       "...         ...         ...      ...    ...      ...   ...    ...    ...\n",
       "9681  0908.2751     math.RA  math.RA   4861      683    51      0     51\n",
       "9682  0908.2942     math.AP  math.AP   7214        0     0      0   3327\n",
       "9683  0908.3174     math.CO  math.CO   2696      391   636   1012    262\n",
       "9684  0908.3636     math.NA  math.NA   1433        0     0      0    147\n",
       "9685  0908.4482     math.AG  math.AG   1940       34     0    375    184\n",
       "\n",
       "[9686 rows x 8 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arxiv_ramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LatestFullRawPease = max(glob.iglob(path+'/pease-data/pease_fullraw*'), key=os.path.getctime)\n",
    "pease_df = pd.read_feather(LatestFullRawPease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2817.640216430051\n"
     ]
    }
   ],
   "source": [
    "outer = 2721.133298/10**6*56794590\n",
    "meta = 4105.898081/10**6*4254638\n",
    "proof = 8009.22507/10**6*19417956\n",
    "print((outer+meta)/(56794590+4254638) *10**6)\n",
    "cat1, cat2 = 'math.HO','math.GM'\n",
    "branch_count1 = 0\n",
    "branch_count2 = 0\n",
    "for j in contexts:\n",
    "    branch_count1 += df_arxiv.loc[(df_arxiv['mainmathcat'] == cat1)][j].sum()\n",
    "    branch_count2 += df_arxiv.loc[(df_arxiv['mainmathcat'] == cat2)][j].sum()\n",
    "explanation_tuple = [[len(explanation_df[explanation_df.mainmathcat==cat1]),branch_count1],\n",
    "[len(explanation_df[explanation_df.mainmathcat==cat2]),branch_count2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Estimate   SE   LCB   UCB  p-value\n",
      "-------------------------------------------------\n",
      "Odds ratio        1.127       1.096 1.159   0.000\n",
      "Log odds ratio    0.120 0.014 0.092 0.148   0.000\n",
      "Risk ratio        1.127       1.096 1.159   0.000\n",
      "Log risk ratio    0.120 0.014 0.092 0.148   0.000\n",
      "-------------------------------------------------\n",
      "difference words -1915802\n",
      "               Estimate   SE   LCB   UCB  p-value\n",
      "-------------------------------------------------\n",
      "Odds ratio        1.360       1.324 1.397   0.000\n",
      "Log odds ratio    0.307 0.014 0.280 0.334   0.000\n",
      "Risk ratio        1.360       1.324 1.397   0.000\n",
      "Log risk ratio    0.307 0.014 0.280 0.334   0.000\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0009697487127103603"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tuple = [[8593,64098066],[11291,94923935]]\n",
    "print(sm.stats.Table2x2(temp_tuple).summary())\n",
    "print('difference words',30892695+31289569-64098066)\n",
    "ramos_expla = [4970+5087,30892695+31289569]\n",
    "my_expla = [11291,94923935]\n",
    "[ramos_expla,my_expla]\n",
    "print(sm.stats.Table2x2([ramos_expla,my_expla]).summary())\n",
    "sm.stats.Table2x2([[156,209],[113,252]]).summary()\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, p, dof, ex = chi2_contingency([[156,209],[113,252]], correction = False)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer pct: 0.5983168523302368\n",
      "outer pct: 0.6733808006001304\n",
      "theorem pct: 0.0651204461761936\n",
      "theorem pct: 0.06380587208356646\n",
      "meta pct: 0.04482155106612468\n",
      "meta pct: 0.03811247596768364\n",
      "proof pct: 0.20456332746846198\n",
      "proof pct: 0.1617691398052478\n",
      "other pct: 0.0871778229589829\n",
      "other pct: 0.06293171154337168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "126.9057747369476"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check context percentages\n",
    "total_my = df_arxiv[['outer','theorem','meta','proof','other']].sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2001.\n",
      "0 2002.\n",
      "0 2003.\n",
      "0 2004.\n",
      "2084 2005.\n",
      "2306 2006.\n",
      "2263 2007.\n",
      "2010 2008.\n",
      "2278 2009.\n",
      "2049 2010.\n",
      "0 2011.\n",
      "0 2012.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,13):\n",
    "    if i < 10:\n",
    "        print(sum(df_arxiv['id'].str.contains('200'+str(i)+'.')),'200'+str(i)+'.')\n",
    "    else:\n",
    "        print(sum(df_arxiv['id'].str.contains('20'+str(i)+'.')),'20'+str(i)+'.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
